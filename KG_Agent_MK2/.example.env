##############################
# GENERAL CONFIGURATION
##############################

# Number of questions to process. Use "0" to process all questions.
NUM_QUESTIONS="5"

# Maximum number of consecutive retry failures before stopping.
MAX_CONSECUTIVE_RETRIES="2"

# Enable or disable annotation of shapes with labels ("True" or "False")
ANNOTATION="True"

# Set to "True" to use a local RDF graph, "False" for remote SPARQL endpoint
IS_LOCAL_GRAPH="True"


##############################
# LOCAL GRAPH CONFIGURATION
##############################

# Path to the local RDF graph file (used only if IS_LOCAL_GRAPH is True)
LOCAL_GRAPH_LOCATION="/absolute/path/to/your_graph.rdf"


##############################
# BENCHMARK INPUT FILE
##############################

# Path to the benchmark dataset (QALD-compatible JSON format)
BASE_JSON_FILE="/absolute/path/to/your_benchmark.json"


##############################
# ENTITY EXTRACTION (LLM)
##############################

# API key for the LLM used in entity extraction
API_KEY_ENTITY_EXTRACTION="your_openai_api_key_here"

# LLM provider for entity extraction ("openai" or "deepseek")
LLM_PROVIDER_ENTITY_EXTRACTION="openai"

# LLM model name for entity extraction
MODEL_ENTITY_EXTRACTION="gpt-4o-mini"

# Max tokens used by the LLM during entity extraction
MAX_TOKENS_ENTITY_EXTRACTION="50"

# Sampling temperature used by the LLM during entity extraction
TEMPERATURE_ENTITY_EXTRACTION="0.2"

# Path to the system prompt file for entity extraction
SYSTEM_PROMPT_ENTITY_EXTRACTION="/absolute/path/to/system_prompt_entity_extraction.txt"


##############################
# SPARQL GENERATION (LLM)
##############################

# API key for the LLM used in SPARQL generation
API_KEY_SPARQL_GENERATION="your_openai_api_key_here"

# LLM provider for SPARQL generation ("openai" or "deepseek")
LLM_PROVIDER_SPARQL_GENERATION="openai"

# LLM model name for SPARQL generation
MODEL_SPARQL_GENERATION="gpt-4o-mini"

# Max tokens used by the LLM during SPARQL generation
MAX_TOKENS_SPARQL_GENERATION="512"

# Sampling temperature used by the LLM during SPARQL generation
TEMPERATURE_SPARQL_GENERATION="0.1"

# Path to the system prompt file for SPARQL generation
SYSTEM_PROMPT_SPARQL_GENERATION="/absolute/path/to/system_prompt_SPARQL_generation.txt"


##############################
# REMOTE SPARQL ENDPOINT (if not using local graph)
##############################

# SPARQL endpoint to query if IS_LOCAL_GRAPH is False
SPARQL_ENDPOINT_URL="https://query.wikidata.org/sparql"
