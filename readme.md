# SPARQL Query Generation Pipeline

A research pipeline that uses Large Language Models (LLMs) to automatically generate SPARQL queries from natural language questions, enhanced with shape-informed prompting for improved accuracy.

## Overview

The pipeline consists of multiple Python scripts, each responsible for a specific task in the **query generation and validation process**. The pipeline evaluates whether providing shape constraints (SHACL/ShEx) to LLMs improves their ability to generate accurate SPARQL queries from natural language questions. The system processes knowledge graph question-answering (KGQA) datasets and measures performance using standard evaluation metrics.

![Artifact Architecture](https://github.com/Branchenprimus/Master-Thesis-Tex/blob/main/images/artifact/architecture_diagram_small.drawio-1.png)
*System architecture showing the complete pipeline flow*
---

## **Pipeline Overview**

### **1Ô∏è‚É£ Extract Entities from NLQs (`extract_entity_list.py`)**
**Goal:** Extract named entities from natural language questions.  
**Inputs:**  
- `--benchmark_dataset` ‚Üí JSON file containing NLQs  
- `--api_key` ‚Üí API key for LLM provider  
- `--num_questions` ‚Üí Number of questions to process  
- `--model` ‚Üí LLM model for entity extraction  
- `--llm_provider` ‚Üí LLM API provider  

**Output:**  
- Extracted entities are stored in `extracted_nlq_sparql_with_entities.json`

---

### **2Ô∏è‚É£ Generate Shape Constraints (`generate_shape.py`)**
**Goal:** Generate **ShEx shapes** (Shape Expressions) for the extracted entities to define constraints for SPARQL queries.  
**Inputs:**  
- `--shape_output_path` ‚Üí Directory for saving shapes  
- `--target_json_file` ‚Üí JSON file containing extracted entities  

**Output:**  
- Generated ShEx shapes in the specified output path.

---

### **3Ô∏è‚É£ Generate SPARQL Queries (`call_llm_api.py`)**
**Goal:** Generate SPARQL queries using an LLM.  
**Inputs:**  
- `--model` ‚Üí LLM model for SPARQL generation  
- `--api_key` ‚Üí API key for LLM provider  
- `--json_path` ‚Üí JSON file with extracted entities  
- `--system_prompt_path` ‚Üí System prompt for the LLM  
- `--shape_path` ‚Üí Path to ShEx shape constraints  
- `--output_dir` ‚Üí Directory for storing LLM-generated SPARQL queries  

**Output:**  
- Generated SPARQL queries are saved in `llm_responses/`

---

### **4Ô∏è‚É£ Execute SPARQL Queries (`call_sparql_endpoint.py`)**
**Goal:** Send both **baseline and LLM-generated** SPARQL queries to **Wikidata** and retrieve results.  
**Inputs:**  
- `--sparql_endpoint_url` ‚Üí URL of the SPARQL endpoint  
- `--json_path` ‚Üí JSON file containing generated SPARQL queries  

**Output:**  
- The results are appended to `extracted_nlq_sparql_with_entities.json`

---

### **5Ô∏è‚É£ Verify SPARQL Query Accuracy (`verify_sparql.py`)**
**Goal:** Compare the LLM-generated SPARQL queries with the baseline to measure correctness.  
**Inputs:**  
- `--json_path` ‚Üí JSON file with SPARQL query results  

**Output:**  
- **Metrics** (Precision, Recall, F1-score) are added to the JSON file.

---

### **6Ô∏è‚É£ Process and Summarize Results (`process_results.py`)**
**Goal:** Aggregate results and generate a summary report.  
**Inputs:**  
- `--json_path` ‚Üí JSON file with verification results  
- `--output_dir` ‚Üí File to save the summary  

**Output:**  
- A text report (`processed.txt`) summarizing:
  - Total queries processed  
  - Correct/incorrect queries  
  - Invalid queries  
  - Precision, Recall, and F1-score  

---

## **1Ô∏è‚É£ Create & Activate a Virtual Environment**

### **On Linux/macOS:**
```sh
python3 -m venv KG_Agent_MK2_venv
source KG_Agent_MK2_venv/bin/activate
```

### **On Windows (PowerShell):**
```powershell
python -m venv KG_Agent_MK2_venv
KG_Agent_MK2_venv\Scripts\activate
```

---

## **2Ô∏è‚É£ Install Dependencies**
Once the virtual environment is activated, install the required Python packages:

```sh
pip install -r requirements.txt
```

---

## **3Ô∏è‚É£ Run the Pipeline**
Execute the **automated shell script** to run the full pipeline:

```sh
bash KG_Agent_MK2.sh
```

### **This script sequentially:**
‚úÖ Extracts named entities from NLQs.  
‚úÖ Generates shape constraints for SPARQL queries.  
‚úÖ Generates SPARQL queries using an LLM.  
‚úÖ Executes SPARQL queries on Wikidata.  
‚úÖ Verifies query accuracy and correctness.  
‚úÖ Processes and summarizes the results.  

---

## **5Ô∏è‚É£ View the Results**
Once execution completes, check the outputs:

### **Final processed results:**
```sh
test/output/processed.txt
```

### **SPARQL query validation results:**
```sh
test/output/extracted_nlq_sparql_with_entities.json
```

### **Log files for debugging:**
```sh
logs/
```

---

## **6Ô∏è‚É£ How to Reinstall or Update the Pipeline**
If you need to update the pipeline:

```sh
git pull origin main
pip install --upgrade -r requirements.txt
```

üöÄ **Now your KG Agent Pipeline is ready to run!** üéØ
## **Results and Evaluation**
- The **final processed results** are saved in `processed.txt`.
- **SPARQL query correctness** is validated using **Precision, Recall, and F1-score**.
- Any **invalid queries or discrepancies** are flagged in the report.

üöÄ **This pipeline automates knowledge graph querying using LLMs and validates results against baseline queries.** üöÄ