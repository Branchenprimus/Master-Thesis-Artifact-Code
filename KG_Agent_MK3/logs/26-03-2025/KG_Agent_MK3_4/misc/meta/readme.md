### **ğŸ“Œ README.md - KG Agent Pipeline**

## **ğŸ”¹ Project Overview**
The **KG Agent** project is designed to extract structured knowledge from natural language queries (NLQs) and generate SPARQL queries to interact with **Wikidata**. The pipeline uses **large language models (LLMs)** to extract relevant entities, generate SPARQL queries, and verify their correctness.

---

## **ğŸ”¹ Pipeline Overview**
The pipeline consists of multiple Python scripts, each responsible for a specific task in the **query generation and validation process**.

### **1ï¸âƒ£ Extract Entities from NLQs (`extract_entity_list.py`)**
ğŸ“Œ **Goal:** Extract named entities from natural language questions.  
ğŸ”¹ **Inputs:**  
- `--benchmark_dataset` â†’ JSON file containing NLQs  
- `--api_key` â†’ API key for LLM provider  
- `--num_questions` â†’ Number of questions to process  
- `--model` â†’ LLM model for entity extraction  
- `--llm_provider` â†’ LLM API provider  

ğŸ”¹ **Output:**  
- Extracted entities are stored in `extracted_nlq_sparql_with_entities.json`

---

### **2ï¸âƒ£ Generate Shape Constraints (`generate_shape.py`)**
ğŸ“Œ **Goal:** Generate **ShEx shapes** (Shape Expressions) for the extracted entities to define constraints for SPARQL queries.  
ğŸ”¹ **Inputs:**  
- `--shape_output_path` â†’ Directory for saving shapes  
- `--target_json_file` â†’ JSON file containing extracted entities  

ğŸ”¹ **Output:**  
- Generated ShEx shapes in the specified output path.

---

### **3ï¸âƒ£ Generate SPARQL Queries (`call_llm_api.py`)**
ğŸ“Œ **Goal:** Generate SPARQL queries using an LLM.  
ğŸ”¹ **Inputs:**  
- `--model` â†’ LLM model for SPARQL generation  
- `--api_key` â†’ API key for LLM provider  
- `--json_path` â†’ JSON file with extracted entities  
- `--system_prompt_path` â†’ System prompt for the LLM  
- `--shape_path` â†’ Path to ShEx shape constraints  
- `--output_dir` â†’ Directory for storing LLM-generated SPARQL queries  

ğŸ”¹ **Output:**  
- Generated SPARQL queries are saved in `llm_responses/`

---

### **4ï¸âƒ£ Execute SPARQL Queries (`call_sparql_endpoint.py`)**
ğŸ“Œ **Goal:** Send both **baseline and LLM-generated** SPARQL queries to **Wikidata** and retrieve results.  
ğŸ”¹ **Inputs:**  
- `--sparql_endpoint_url` â†’ URL of the SPARQL endpoint  
- `--json_path` â†’ JSON file containing generated SPARQL queries  

ğŸ”¹ **Output:**  
- The results are appended to `extracted_nlq_sparql_with_entities.json`

---

### **5ï¸âƒ£ Verify SPARQL Query Accuracy (`verify_sparql.py`)**
ğŸ“Œ **Goal:** Compare the LLM-generated SPARQL queries with the baseline to measure correctness.  
ğŸ”¹ **Inputs:**  
- `--json_path` â†’ JSON file with SPARQL query results  

ğŸ”¹ **Output:**  
- **Metrics** (Precision, Recall, F1-score) are added to the JSON file.

---

### **6ï¸âƒ£ Process and Summarize Results (`process_results.py`)**
ğŸ“Œ **Goal:** Aggregate results and generate a summary report.  
ğŸ”¹ **Inputs:**  
- `--json_path` â†’ JSON file with verification results  
- `--output_dir` â†’ File to save the summary  

ğŸ”¹ **Output:**  
- A text report (`processed.txt`) summarizing:
  - Total queries processed  
  - Correct/incorrect queries  
  - Invalid queries  
  - Precision, Recall, and F1-score  

---

## **ğŸ”¹ 1ï¸âƒ£ Create & Activate a Virtual Environment**

### **On Linux/macOS:**
```sh
python3 -m venv KG_Agent_MK2_venv
source KG_Agent_MK2_venv/bin/activate
```

### **On Windows (PowerShell):**
```powershell
python -m venv KG_Agent_MK2_venv
KG_Agent_MK2_venv\Scripts\activate
```

---

## **ğŸ”¹ 2ï¸âƒ£ Install Dependencies**
Once the virtual environment is activated, install the required Python packages:

```sh
pip install -r requirements.txt
```

---

## **ğŸ”¹ 3ï¸âƒ£ Run the Pipeline**
Execute the **automated shell script** to run the full pipeline:

```sh
bash KG_Agent_MK2.sh
```

### **This script sequentially:**
âœ… Extracts named entities from NLQs.  
âœ… Generates shape constraints for SPARQL queries.  
âœ… Generates SPARQL queries using an LLM.  
âœ… Executes SPARQL queries on Wikidata.  
âœ… Verifies query accuracy and correctness.  
âœ… Processes and summarizes the results.  

---

## **ğŸ”¹ 5ï¸âƒ£ View the Results**
Once execution completes, check the outputs:

### **Final processed results:**
```sh
test/output/processed.txt
```

### **SPARQL query validation results:**
```sh
test/output/extracted_nlq_sparql_with_entities.json
```

### **Log files for debugging:**
```sh
logs/
```

---

## **ğŸ”¹ 6ï¸âƒ£ How to Reinstall or Update the Pipeline**
If you need to update the pipeline:

```sh
git pull origin main
pip install --upgrade -r requirements.txt
```

ğŸš€ **Now your KG Agent Pipeline is ready to run!** ğŸ¯
## **ğŸ”¹ Results and Evaluation**
- The **final processed results** are saved in `processed.txt`.
- **SPARQL query correctness** is validated using **Precision, Recall, and F1-score**.
- Any **invalid queries or discrepancies** are flagged in the report.

ğŸš€ **This pipeline automates knowledge graph querying using LLMs and validates results against baseline queries.** ğŸš€